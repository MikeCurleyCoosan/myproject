 TaskList

- [ ] Source and investigate sets of data
- [ ] Programmatically explore and visualise data
- [ ] Apply basic mathematical data analysis techniques to data sets
- [ ] Model real-world problems for analysis by computer
- [ ] Provide evidence in a decision-making process using a data set.
- [ ] Appreciate the limitations of graphical representations in data intensive workflows.


TASKS(40%)

- [x] Create a GitHub repository with a README.md and a .gitignore. Add a jupyter notebook called penguins.ipynb and add a title to it.
- [x] Find the palmerpenguins data set online and load it into your Jupyter notebook. In your notebook, give an overview of the dataset
      and the variables it contains,
- [ ] Suggest the types of variables that should be used to model the variables in the data set in Python, explaining your rationale.
- [x] Create a bar chart of an appropriate variable in the data-set. Then create a histogram of an appropriate vairable in the data set.

PROJECT(40%)

- [ ] Select two variables from the data set and provied analysis of how correlated they are.

Presentation(20%)

- [ ] Ensure your repository is tidy, with no unnecessary items. Ensure your README>md and .gitignore files are appropriate. Make sure
      your notebook contains a single cohesive narrative about the dataset.

Marking Scheme

Research
- [ ] Evidence of research
- [ ] Appropiate referencing
- [ ] Building on work in the literature
- [ ] Comparison to similar work

Development
- [ ] Clear, concise, and correct code
- [ ] Appropriate tests
- [ ] Demonstrate knowledge of different approaches and algorithms
- [ ] Clean architecture

Documentation
- [ ] Clear explanations of concepts in notebooks
- [ ] Concise comments in code and elsewhere
- [ ] Appropriate, standard README for a GitHub repository.

Consistency
- [ ] Lots of commits, each representing a reasonable amount of work
- [ ] Literature, documentation, and code evidencing work on the assessment.
- [ ] Evidence of review and refactoring.
